{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "colab": {
      "name": "siamese_omniglot_triplet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdo1j7-IKV4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c27bead4-1232-4c94-d429-e725474a81f6"
      },
      "source": [
        "!curl --header \"Host: storage.googleapis.com\" --header \"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-US,en;q=0.9\" --header \"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/57364%2F110433%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1596444262&Signature=K1BYbE%2B4tSN1AVXTBUzrhopSGhNvmgdSmLabk7e5jVmmYyrFoVqT0s6JGSUa2cGiF7taa4djxQWjlBYq4Icg3v4oNfjGREE0MAXzKaF6CsxP2W5KksjwqRHLHiH3rGKZ1wVBgXQ3I3%2Fn8bZ%2FQMpnVRW3xuyZ9M6uHAqngS8HDdIl%2FcI2GYQN55HoFfz7EbQc2p3VBGz4lP%2BG6ST8NUlobUjJE9BtYX4Q2gwQb1%2Ba2Kw5Q7J6wbvPsa2e9i96DmV3KIPamA4fPS2Mtk%2Frw91NNv7zI6D1QSsGEpgCmXZwC5Sej8fNbxIxjQGkRUkvZZALG%2BswfGE5BPFQ6fhbkPAzFA%3D%3D\" -L -o 'omniglot.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 30.0M  100 30.0M    0     0  62.9M      0 --:--:-- --:--:-- --:--:-- 62.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4hMAItHLCGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip omniglot.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbs0Vwl_mRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e486e5ea-e79e-481d-b8ee-d7f8ac14d605"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oB9sPYFI1Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "import PIL\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5rH3tuKfhKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(save_path, model, optimizer, val_loss):\n",
        "  state_dict = {\n",
        "      'model': model.state_dict(),\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'val_loss': val_loss\n",
        "  }\n",
        "  torch.save(state_dict, save_path)\n",
        "  print(f'model saved to {save_path}')\n",
        "\n",
        "def load_model(load_path, model, optimizer):\n",
        "  state_dict = torch.load(load_path)\n",
        "  model.load_state_dict(state_dict['model'])\n",
        "  optimizer.load_state_dict(state_dict['optimizer'])\n",
        "  print(f'Model loaded from {load_path}')\n",
        "  return state_dict['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6lgujpoI1Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'images_background/'\n",
        "#train_dict = read_files(train_dir)\n",
        "\n",
        "# test_dir = 'data/omniglot/images_evaluation/'\n",
        "# test_dict = read_files(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO7-_l0PI1Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxb6AA6wdHvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestData(Dataset):\n",
        "  def __init__(self, data_path, data_size, n_ways, transforms=None):\n",
        "    super(TestData, self).__init__()\n",
        "    self.data_size = data_size\n",
        "    self.data_path = data_path\n",
        "    self.n_ways = n_ways\n",
        "    self.transforms = transforms\n",
        "    self.data_dict = self.read_files()\n",
        "\n",
        "  def read_files(self):\n",
        "      work_dir = os.getcwd()\n",
        "      os.chdir(self.data_path)\n",
        "      data_dict = defaultdict(dict)\n",
        "\n",
        "      try:\n",
        "          for file in glob.glob('./*/*'):\n",
        "              path_split = file.split('/')[1:]\n",
        "              data_dict[path_split[0]][path_split[1]] = os.listdir(file)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "          os.chdir(work_dir)\n",
        "      os.chdir(work_dir)\n",
        "\n",
        "      return data_dict\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.data_size\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    test_set = []\n",
        "    target_cat = random.choice(list(self.data_dict.keys()))\n",
        "    target_char = random.choice(list(self.data_dict[target_cat].keys()))\n",
        "    main_img = random.choice(self.data_dict[target_cat][target_char])\n",
        "    main_img = '/'.join([target_cat, target_char, main_img])\n",
        "\n",
        "    label = random.randint(0, self.n_ways-1)\n",
        "    for i in range(self.n_ways):\n",
        "      if i == label:\n",
        "        img = random.choice(list(set(self.data_dict[target_cat][target_char])-set(main_img)))\n",
        "        img = '/'.join([target_cat, target_char, img])\n",
        "        test_set.append(img)\n",
        "        continue\n",
        "      \n",
        "      if random.random() > 0.3:\n",
        "        char = random.choice(list(set(self.data_dict[target_cat].keys())-set([target_char])))\n",
        "        img =  random.choice(self.data_dict[target_cat][char])\n",
        "        img = '/'.join([target_cat, char, img])\n",
        "        test_set.append(img)\n",
        "      else:\n",
        "        cat = random.choice(list(set(self.data_dict.keys())-set([target_cat])))\n",
        "        char = random.choice(list(self.data_dict[cat].keys()))\n",
        "        img = random.choice(self.data_dict[cat][char])\n",
        "        img = '/'.join([cat, char, img])\n",
        "        test_set.append(img)\n",
        "    if self.transforms:\n",
        "      main_img = self.transforms(PIL.Image.open(self.data_path + '/' + main_img))\n",
        "      test_set = [self.transforms(PIL.Image.open(self.data_path + '/' + img)) for img in test_set]\n",
        "      test_set = torch.stack(test_set)\n",
        "    return (main_img, test_set, torch.tensor([label], dtype=torch.float))\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPegQ6imXq5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "64dcc6d4-0d59-4f66-b13f-903fc6d40db0"
      },
      "source": [
        "main_img, test_set, label = next(iter(test_loader))\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "test_set = test_set.squeeze(0)\n",
        "num_test = test_set.shape[0]\n",
        "\n",
        "ax1 = fig.add_subplot(2,num_test,label.item()+1, xticks=[], yticks=[])\n",
        "img = main_img.numpy().squeeze(0).squeeze(0)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "ax1.imshow(img)\n",
        "for i in range(num_test):\n",
        "    \n",
        "    ax2 = fig.add_subplot(2, num_test, i+1+num_test, xticks=[], yticks=[])\n",
        "    img = test_set[i].numpy().squeeze(0)\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    ax2.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zAFb9ZdBnI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_sample(main_img, test_set, label):\n",
        "  fig = plt.figure(figsize=(25,4))\n",
        "  test_set = test_set.squeeze(0)\n",
        "  num_test = test_set.shape[0]\n",
        "\n",
        "  ax1 = fig.add_subplot(2,num_test,label.item()+1, xticks=[], yticks=[])\n",
        "  img = main_img.numpy().squeeze(0).squeeze(0)\n",
        "  plt.subplots_adjust(wspace=0, hspace=0)\n",
        "  ax1.imshow(img)\n",
        "  for i in range(num_test):\n",
        "      \n",
        "      ax2 = fig.add_subplot(2, num_test, i+1+num_test, xticks=[], yticks=[])\n",
        "      img = test_set[i].numpy().squeeze(0)\n",
        "      plt.subplots_adjust(wspace=0, hspace=0)\n",
        "      ax2.imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVo4ml0AYUc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(model, test_data, n_ways):\n",
        "  test_data = TestData('images_evaluation', 1000, n_ways, transforms=img_transform)\n",
        "  test_loader = DataLoader(test_data, shuffle=True)\n",
        "  d = nn.PairwiseDistance(p=2)\n",
        "  model = model.to(device)\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for main_img, test_set, label in test_loader:\n",
        "      main = main_img.repeat(n_ways,1,1,1)\n",
        "      main = main.to(device)\n",
        "      target = test_set.to(device).squeeze(0)\n",
        "      main_emb, test_emb = model(main, target)\n",
        "      dist = d(main_emb, test_emb)\n",
        "      pred_label = torch.argmin(dist)\n",
        "      a, b = torch.sort(dist).values[:2]\n",
        "      if (pred_label.item() == label.item() and (b-a).item() >= 0.4):\n",
        "        predictions.append(1)\n",
        "      else:\n",
        "        predictions.append(0)\n",
        "        display_sample(main_img, test_set, pred_label)\n",
        "    return np.mean(predictions) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqyLoO9ngeT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TripletData(Dataset):\n",
        "  def __init__(self, data_path, data_size, transforms=None):\n",
        "    super(TripletData, self).__init__()\n",
        "    self.data_path = data_path\n",
        "    self.data_size = data_size\n",
        "    self.transforms = transforms\n",
        "    self.data_dict = self.read_files()\n",
        "    self.category = list(self.data_dict.keys())\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.data_size\n",
        "  \n",
        "  def read_files(self):\n",
        "        work_dir = os.getcwd()\n",
        "        os.chdir(self.data_path)\n",
        "        data_dict = defaultdict(dict)\n",
        "\n",
        "        try:\n",
        "            for file in glob.glob('./*/*'):\n",
        "                path_split = file.split('/')[1:]\n",
        "                data_dict[path_split[0]][path_split[1]] = os.listdir(file)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            os.chdir(work_dir)\n",
        "        os.chdir(work_dir)\n",
        "\n",
        "        return data_dict\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    cats = random.sample(self.category, 2)\n",
        "    chars = random.sample(list(self.data_dict[cats[0]].keys()), 2)\n",
        "    anchor_img, pos_img = random.sample(self.data_dict[cats[0]][chars[0]], 2)\n",
        "    anchor_img = '/'.join([cats[0], chars[0], anchor_img])\n",
        "    pos_img = '/'.join([cats[0], chars[0], pos_img])\n",
        "    neg_img = None\n",
        "\n",
        "    if random.random() > 0.3:\n",
        "      char = random.choice(list(self.data_dict[cats[1]].keys()))\n",
        "      neg_img = random.choice(self.data_dict[cats[1]][char])\n",
        "      neg_img = '/'.join([cats[1], char, neg_img])\n",
        "    else:\n",
        "      neg_img = random.choice(self.data_dict[cats[0]][chars[1]])\n",
        "      neg_img = '/'.join([cats[0], chars[1], neg_img])\n",
        "    \n",
        "    anchor_img = self.transforms(PIL.Image.open(self.data_path + '/' + anchor_img))\n",
        "    pos_img = self.transforms(PIL.Image.open(self.data_path + '/' + pos_img))\n",
        "    neg_img = self.transforms(PIL.Image.open(self.data_path + '/' + neg_img))\n",
        "    \n",
        "    return (anchor_img, pos_img, neg_img)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I77-pY4WFT-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet_data = TripletData('images_background', 50000, img_transform)\n",
        "train_set, val_set = random_split(triplet_data, [40000, 10000])\n",
        "train_loader = DataLoader(train_set, 256)\n",
        "valid_loader = DataLoader(val_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up0akqQzLQeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def criterion(anchor_emb, pos_emb, neg_emb):\n",
        "#   pos_dist = torch.sum(torch.square(anchor_emb-pos_emb))\n",
        "#   neg_dist = torch.sum(torch.square(anchor_emb-neg_emb))\n",
        "  \n",
        "#   loss = (pos_dist-neg_dist + anchor_emb.shape[0] * anchor_emb.shape[1])/(anchor_emb.shape[0])\n",
        "#   return loss\n",
        "\n",
        "def criterion(a, p, n, margin=0.5) : \n",
        "    d = nn.PairwiseDistance(p=2)\n",
        "    distance = d(a, p) - d(a, n) + margin \n",
        "    loss = torch.mean(torch.max(distance, torch.zeros_like(distance))) \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rev4R5hYf8HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNet, self).__init__()\n",
        "        \n",
        "        ###Kernals\n",
        "        self.conv1 = nn.Conv2d(1,64,10)\n",
        "        self.conv2 = nn.Conv2d(64,128,7)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "\n",
        "        ###Batch Norm\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        ####Dropout\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        ###FC layer\n",
        "        self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "        self.fcOut = nn.Linear(4096, 256)\n",
        "\n",
        "        ###Final output\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def convs(self, x):\n",
        "        # 1, 105, 105\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # 64, 96, 96\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 64, 48, 48\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        # 128, 42, 42\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 128, 21, 21\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        #128, 18, 18\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        #128, 9, 9\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        #256, 6, 6\n",
        "        return x\n",
        "\n",
        "    def forward(self, anch, pos, neg=None):\n",
        "        anch = self.convs(anch)\n",
        "        anch = anch.view(-1, 256*6*6)\n",
        "        anch = F.relu(self.fc1(anch))\n",
        "        anch = F.relu(self.fcOut(anch))\n",
        "\n",
        "        pos = self.convs(pos)\n",
        "        pos = pos.view(-1, 256*6*6)\n",
        "        pos = F.relu(self.fc1(pos))\n",
        "        pos = F.relu(self.fcOut(pos))\n",
        "        \n",
        "        if neg != None:\n",
        "          neg = self.convs(neg)\n",
        "          neg = neg.view(-1, 256*6*6)\n",
        "          neg = F.relu(self.fc1(neg))\n",
        "          neg = F.relu(self.fcOut(neg))\n",
        "          return anch, pos, neg\n",
        "\n",
        "        return anch, pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vT5G9wqjIWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9o0yectkGAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "050c4525-194b-4793-ad44-cafdbae6d6dd"
      },
      "source": [
        "model = SiameseNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "load_model('drive/My Drive/Omniglot_siamese/triplet_model.pt', model, optimizer)\n",
        "model = model.to(device)\n",
        "\n",
        "#train_loss, validation_loss = train(model, train_loader, valid_loader, 50, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from drive/My Drive/Omniglot_siamese/triplet_model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVnSWIvNzEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#eval(model, test_loader, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DoClg3SRPow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = TripletData('images_background', 128)\n",
        "data_dict = loader.read_files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2N0C_AVEwow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_num = 16\n",
        "neg_num = 200\n",
        "\n",
        "cats = random.sample(list(data_dict.keys()), 2)\n",
        "chars = random.sample(list(data_dict[cats[0]]), 2)\n",
        "pos_imgs = random.sample((data_dict[cats[0]][chars[0]]), pos_num)\n",
        "pos_imgs = ['/'.join(['images_background', cats[0], chars[0], img]) for img in pos_imgs]\n",
        "\n",
        "neg_imgs = []\n",
        "for i in range(neg_num):\n",
        "  if random.random() < 0.8:\n",
        "    neg_img = random.choice((data_dict[cats[0]][chars[1]]))\n",
        "    neg_imgs.append('/'.join(['images_background', cats[0],chars[1], neg_img]))\n",
        "  else:\n",
        "    cat = random.choice(list(set(data_dict.keys()) - set([cats[0]])))\n",
        "    char = random.choice(list(data_dict[cat]))\n",
        "    img = random.choice(data_dict[cat][char])\n",
        "    neg_imgs.append('/'.join(['images_background', cat,char, img]))\n",
        "\n",
        "main_img = img_transform(PIL.Image.open(pos_imgs[0]))\n",
        "pos = torch.stack([img_transform(PIL.Image.open(img)) for img in pos_imgs[1:]]).to(device)\n",
        "neg = torch.stack([img_transform(PIL.Image.open(img)) for img in neg_imgs]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  embed_pos = model(main_img.repeat(pos_num-1,1,1,1).to(device), pos)\n",
        "  embed_neg = model(main_img.repeat(neg_num,1,1,1).to(device), neg)\n",
        "\n",
        "d = nn.PairwiseDistance(p=2)\n",
        "pos_dist = d(embed_pos[0], embed_pos[1])\n",
        "neg_dist = d(embed_neg[0], embed_neg[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXgAgJ_AWfan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}