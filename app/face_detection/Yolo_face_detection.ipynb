{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-z_TsM8qA1hz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from parse_config import parse_model_config\n",
    "from models import Darknet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWqLJ3J9DHAS"
   },
   "outputs": [],
   "source": [
    "LABELLED_DATA_PATH = 'data/train_images/'\n",
    "\n",
    "def img_transform(img_path, boxes):\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "    square_dim = max(w,h)\n",
    "    pad_len = abs(w-h)//2\n",
    "    pad_dim = (0,0, 0,0, pad_len, pad_len) if w >= h else (0,0, pad_len,pad_len, 0,0)\n",
    "    img = F.pad(torch.from_numpy(img), pad_dim, )\n",
    "    shift_x, shift_y = (0, pad_len) if w>=h else (pad_len, 0)\n",
    "    boxes = torch.IntTensor(boxes)\n",
    "    boxes[..., :2] += torch.IntTensor([shift_x, shift_y])\n",
    "    boxes[:, :2] += (boxes[:, 2:]//2)\n",
    "    boxes = boxes/float(img.shape[0])\n",
    "    img = F.interpolate(img.permute(2,0,1).unsqueeze(0), size=416, mode='nearest').float().squeeze(0)\n",
    "    return img, boxes\n",
    "\n",
    "def draw_boxes(img, box_norm):\n",
    "    h, w = img.shape[:2]\n",
    "    square_dim = max(w,h)\n",
    "    pad_len = abs(w-h)//2\n",
    "    boxes = (box_norm * w).astype(int)\n",
    "    shift_x, shift_y = (0, pad_len) if w>=h else (pad_len, 0)\n",
    "    print(pad_len)\n",
    "    boxes[:, :2] -= [shift_x, shift_y]\n",
    "    boxes[:, :2] -= (boxes[:, 2:]//2)\n",
    "    for x1, y1, w, h in boxes:\n",
    "        cv2.rectangle(img, (x1, y1), (x1+w, y1+h), (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "class FaceTrainSet(Dataset):\n",
    "    def __init__(self, data_path, labels_path, transforms=None):\n",
    "        super(FaceTrainSet, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.labels_path = labels_path\n",
    "\n",
    "        self.labels = np.loadtxt(self.labels_path, dtype=str, delimiter='\\n')\n",
    "        self.file_names = list(filter(lambda x:x.endswith('.jpg'), self.labels))\n",
    "        self.file_name_index = [i for i in range(len(self.labels)) if self.labels[i].endswith('.jpg')]\n",
    "        \n",
    "        self.batch_count = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.file_name_index[index]\n",
    "        try:\n",
    "            label_info = self.labels[idx: self.file_name_index[self.file_name_index.index(idx)+1]]\n",
    "        except IndexError as e:\n",
    "            label_info = self.labels[idx:]\n",
    "        file_name = label_info[0]\n",
    "        num_faces = label_info[1]\n",
    "        box_dims = [np.array(values.split()).astype(np.int)[:4] for values in label_info[2:]]\n",
    "        img_tensor, boxes = img_transform(LABELLED_DATA_PATH+file_name, box_dims)\n",
    "        return (img_tensor, boxes, num_faces)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        img_tensors, targets, num_faces = list(zip(*batch))\n",
    "        # Remove empty placeholder targets\n",
    "        targets = [boxes for boxes in targets if boxes is not None] \n",
    "        # Add sample index to targets\n",
    "        for i, boxes in enumerate(targets):\n",
    "            index = torch.ones(len(boxes), 1) * i\n",
    "            targets[i] = torch.cat((index, boxes), 1)\n",
    "        targets = torch.cat(targets, 0)\n",
    "        # Selects new image size every tenth batch\n",
    "        #         if self.multiscale and self.batch_count % 10 == 0:\n",
    "        #             self.img_size = random.choice(range(self.min_size, self.max_size + 1, 32))\n",
    "        #         # Resize images to input shape\n",
    "        #         imgs = torch.stack([resize(img, self.img_size) for img in imgs])\n",
    "        img_tensors = torch.stack([img for img in img_tensors])\n",
    "        self.batch_count += 1\n",
    "        return img_tensors, targets, num_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKbcXO3t-wDh"
   },
   "outputs": [],
   "source": [
    "dataset = FaceTrainSet('data/train_images/', 'data/labels.txt')\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn = dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensors, boxes, num_faces = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet('yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out= model(img_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(pred_boxes, object_pred, target, anchors, obj_thres):\n",
    "    ByteTensor = torch.cuda.ByteTensor if predictions.is_cuda else torch.ByteTensor\n",
    "    FloatTensor = torch.cuda.FloatTensor if predictions.is_cuda else torch.floatTensor\n",
    "\n",
    "    nS = pred_boxes.size(0)\n",
    "    nA = pred_boxes.size(1)\n",
    "    nG = pred_boxes.size(2)\n",
    "\n",
    "    # Output tensors\n",
    "    obj_mask = ByteTensor(nB, nA, nG, nG).fill_(0)\n",
    "    noobj_mask = ByteTensor(nB, nA, nG, nG).fill_(1)\n",
    "    iou_scores = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
    "    tx = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
    "    ty = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
    "    tw = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
    "    th = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
    "\n",
    "    target_boxes = target[..., 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Yolo_face_detection.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
